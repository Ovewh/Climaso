{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d028b3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import theilslopes\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from pyclim_noresm.general_util_funcs import global_avg,mask_region_latlon\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.tsatools import detrend, add_trend\n",
    "import statsmodels.tsa.api as tsa\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "from statsmodels.tsa.stattools import adfuller\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0208e634-bd42-450d-b04d-3e3e726b6615",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets_histSST = [xr.open_dataset(p) for p in snakemake.input.histSST]\n",
    "dsets_histSST = {f'{ds.source_id}_{ds.variable_id}' : ds for ds in dsets_histSST}\n",
    "dsets_piClim_aer = [xr.open_dataset(p) for p in snakemake.input.piClim_aer]\n",
    "dsets_piClim_aer = {f'{ds.source_id}_{ds.variable_id}' : ds for ds in dsets_piClim_aer}\n",
    "forcing_estimates = pd.read_csv('workflow/input_data/Smith_forcing_trends.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "954a410f-2d60-4121-8922-2e74aeb3896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "forcing_regions = {\n",
    "    'East China': {'lon0':80, 'lat0':25, 'lon1':145,'lat1':50},\n",
    "    'India'     : {'lon0':63, 'lat0':5,'lon1':93,'lat1':30},\n",
    "    'Europe'    : {'lon0':-5, 'lat0':35, 'lon1':40,'lat1':65},\n",
    "    'North America': {'lon0':-100, 'lat0': 23, 'lon1':-50, 'lat1':53},\n",
    "    'Global'       : {'lon0':None, 'lat0': None, 'lon1': None, 'lat1':None}\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee42929c-28d1-488e-acec-174a60ad2765",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig ,ax = plt.subplots(figsize=(12,7), subplot_kw={'projection': ccrs.Robinson()})\n",
    "ax.set_global()\n",
    "ax.add_patch(mpl.patches.Rectangle(xy=[80,25],width=65,height=25, transform=ccrs.PlateCarree(),\n",
    "                                   fill=False, edgecolor='tab:blue', linewidth=2))\n",
    "\n",
    "ax.add_patch(mpl.patches.Rectangle(xy=[-5,35],width=50,height=30, transform=ccrs.PlateCarree(),\n",
    "                                   fill=False, edgecolor='tab:orange', linewidth=2))\n",
    "\n",
    "ax.add_patch(mpl.patches.Rectangle(xy=[-100,23],width=50,height=30, transform=ccrs.PlateCarree(),\n",
    "                                   fill=False, edgecolor='tab:purple', linewidth=2))\n",
    "\n",
    "ax.add_patch(mpl.patches.Rectangle(xy=[63,5],width=30,height=25, transform=ccrs.PlateCarree(),\n",
    "                                   fill=False, edgecolor='tab:green', linewidth=2))\n",
    "\n",
    "\n",
    "ax.coastlines()\n",
    "# ax.set_xticks([-180,-140,-100,-60, -20, 20 , 60, 100, 140, 180], crs=ccrs.PlateCarree())\n",
    "# ax.set_yticks([-90,-70,-50,-30,-10,10,30,50,70,90])\n",
    "gl = ax.gridlines()\n",
    "gl.left_labels=True\n",
    "gl.bottom_labels=True\n",
    "# gl.xlocator(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3369a9d6-afc9-4802-893e-c97502225284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regional_create_time_series(dsets: dict, region_dict:dict, norm=False, standardize=False,hist=True):\n",
    "    out_dict = {}\n",
    "    for source_id, ds in dsets.items():\n",
    "        for region, c in region_dict.items():\n",
    "            shift=0\n",
    "            if ds.lon.max() > 356:\n",
    "                shift = 180 \n",
    "            if region == 'Global':\n",
    "                temp_ds = ds[ds.variable_id]\n",
    "            else:\n",
    "                \n",
    "                temp_ds = ds[ds.variable_id].sel(lon=slice(c['lon0']+shift, c['lon1']+shift), lat=slice(c['lat0'],c['lat1']))\n",
    "            if 'year' in temp_ds.dims:\n",
    "                temp_ds = temp_ds.rename({'year':'time'})\n",
    "            if temp_ds.time[0].dtype == 'O':\n",
    "                temp_ds = temp_ds.assign_coords(time=temp_ds.indexes['time'].to_datetimeindex())\n",
    "            temp_ds = global_avg(temp_ds)\n",
    "            \n",
    "            temp_ds = temp_ds\n",
    "            if norm:\n",
    "                temp_ds = (temp_ds-temp_ds.min(axis=0)/(temp_ds.max(axis=0)-temp_ds.min(axis=0)))\n",
    "            elif standardize:\n",
    "                temp_ds = (temp_ds-temp_ds.mean(axis=0)/(temp_ds.std(axis=0)))\n",
    "            if hist:\n",
    "                out_dict[f'{region}_{source_id}'] = temp_ds.to_pandas()\n",
    "            else:\n",
    "                temp_ds = temp_ds.to_pandas().reset_index()\n",
    "                out_dict[f'{region}_{source_id}'] = temp_ds.drop(columns=['time'])[0]\n",
    "    if hist==False:\n",
    "        index = temp_ds.index\n",
    "        df = pd.DataFrame(out_dict, index=index, columns=out_dict.keys())\n",
    "    else:\n",
    "        df = pd.DataFrame(out_dict)\n",
    "    return df\n",
    "\n",
    "\n",
    "def _testStationary(df, key=None, resamplingAvg=None, confidence_level=0.95):\n",
    "    if resamplingAvg != None:\n",
    "        df = df.resample(resamplingAvg).mean()\n",
    "\n",
    "    print(\" > Is the data stationary ?\")\n",
    "    try:\n",
    "        if key==None:\n",
    "            key = df.keys()[0]\n",
    "        dftest = adfuller(df[key].dropna(), autolag='AIC')\n",
    "    except AttributeError:\n",
    "        dftest = adfuller(df,autolag='AIC')\n",
    "    print(\"Test statistic = {:.3f}\".format(dftest[0]))\n",
    "    print(\"P-value = {:.3f}\".format(dftest[1]))\n",
    "    print(\"Critical values :\")\n",
    "    for k, v in dftest[4].items():\n",
    "        print(\"\\t{}: {} - The data is {} stationary with {}% confidence\".format(k, v, \"not\" if v<dftest[0] else \"\", 100-int(k[:-1])))\n",
    "\n",
    "\n",
    "def add_linear_trends(df, a=1, c=0):\n",
    "    trend = add_trend(df, 'ct')\n",
    "    t = trend['trend']*a\n",
    "    const = c\n",
    "    trend = trend.add(t+const, axis=0)\n",
    "    trend['const'] = const \n",
    "    trend['trend'] = t\n",
    "    \n",
    "    return trend\n",
    "\n",
    "def MK_test(x ,verbose=True):\n",
    "    n = len(x)\n",
    "    S = 0\n",
    "    for i in range(n-1):\n",
    "        for j in range(i+1, n):\n",
    "            S += np.sign(x[j] - x[i])\n",
    "\n",
    "    # number of tied groups\n",
    "    q = len(np.unique(x)) # number of unique values\n",
    "\n",
    "    # number of ties for the p-th value\n",
    "    tp = np.zeros(np.unique(x).shape)\n",
    "    for i in range(q):\n",
    "        tp[i] = sum(x == np.unique(x)[i])\n",
    "\n",
    "    var_s = (n*(n-1)*(2*n+5) - np.sum(tp*(tp-1)*(2*tp+5)))/18\n",
    "\n",
    "    # calculate the MK test statistic Z_MK\n",
    "    if S > 0:\n",
    "        Z_MK = (S - 1)/np.sqrt(var_s)\n",
    "    elif S < 0:\n",
    "        Z_MK = (S + 1)/np.sqrt(var_s)\n",
    "    else:\n",
    "        Z_MK = 0\n",
    "\n",
    "    # calculate the p_value\n",
    "    p = 2*(1-norm.cdf(abs(Z_MK))) #two tailed test\n",
    "    if verbose:\n",
    "        print(\"sample size=\"+str(n))\n",
    "        print(\"S=\"+str(S))\n",
    "        print(\"var(S)=\"+str(var_s))\n",
    "        print(\"Z_MK=\"+str(Z_MK))\n",
    "        print(\"p-value=\"+str(p))\n",
    "\n",
    "    return p\n",
    "\n",
    "def rolling_detrend(df, windowsize=3):\n",
    "    return df-df.rolling(windowsize, center=True).mean()/df.rolling(windowsize, center=True).std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "34ef13f5-0019-471b-ab69-7bc234c3ae30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def artificial_trend_analysis(df: pd.DataFrame, \n",
    "                              trend: float, \n",
    "                              region : str = 'Global', \n",
    "                              intercept: float = 0.0, hist=True):\n",
    "    vname = df.columns[0].split('_')[-1]\n",
    "    models = list(set([c.split('_')[1] for c in df.columns]))\n",
    "\n",
    "    if hist:\n",
    "        detrended = df.diff()\n",
    "        var_PI = detrended.loc['1860':'1890']\n",
    "        var_1950 = detrended.loc['1950':'1980']\n",
    "        var_1980 = detrended.loc['1980':'2010']\n",
    "    else:\n",
    "        var_PI = df.iloc[5:30,:] - df.iloc[5:30,:].mean()\n",
    "    trend_pi = add_linear_trends(var_PI, trend) \n",
    "    if hist:\n",
    "        trend_1950 = add_linear_trends(var_1950, forcing_estimates.loc['CMIP6-constrained','mean']) \n",
    "        trend_1980 = add_linear_trends(var_1980, forcing_estimates.loc['CMIP6-constrained','mean']) \n",
    "    out_df = pd.DataFrame(columns=models+ ['True trend'], index=['PI','1950','1980'])\n",
    "    significance =  pd.DataFrame(columns=models, index=['PI','1950','1980'])\n",
    "    out_df['True trend'] = trend \n",
    "    for model in models:\n",
    "        X = sm.add_constant(np.arange(0,len(trend_pi[f'{region}_{model}_{vname}'])))\n",
    "\n",
    "        result_pi = sm.OLS(trend_pi[f'{region}_{model}_{vname}'],X).fit()\n",
    "        significance.loc['PI',model] = MK_test(trend_pi[f'{region}_{model}_{vname}'].values, verbose=False) < 0.05\n",
    "\n",
    "        out_df.loc['PI',model] = result_pi.params[1]\n",
    "        if hist:\n",
    "            result_1950 = sm.OLS(trend_1950[f'{region}_{model}_{vname}'],X).fit()\n",
    "            result_1980 = sm.OLS(trend_1980[f'{region}_{model}_{vname}'],X).fit()\n",
    "            significance.loc['1950',model] = MK_test(trend_1950[f'{region}_{model}_{vname}'].values, verbose=False) < 0.05\n",
    "            significance.loc['1980',model] = MK_test(trend_1980[f'{region}_{model}_{vname}'].values, verbose=False) < 0.05\n",
    "            out_df.loc['1950',model] = result_1950.params[1]\n",
    "            out_df.loc['1980',model] = result_1980.params[1]\n",
    "        \n",
    "\n",
    "\n",
    "    return out_df, significance\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "148b09e8-5ed9-43d3-86d8-0abbf7d0747b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pi = regional_create_time_series(dsets_piClim_aer, forcing_regions, standardize=False, hist=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce85216d-50ba-492c-b5da-fac82f6bef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = regional_create_time_series(dsets_histSST, forcing_regions, standardize=False)\n",
    "df_pi = regional_create_time_series(dsets_piClim_aer, forcing_regions, standardize=False, hist=False)\n",
    "detrended = df.diff()\n",
    "trenddf ,r = artificial_trend_analysis(df, forcing_estimates.loc['CMIP6-constrained','mean'])\n",
    "var_PI = detrended.loc['1860':'1890']\n",
    "var_1950 = detrended.loc['1950':'1980']\n",
    "var_1980 = rolling_detrend(df.loc['1980':'2010'])\n",
    "# detrended_PI = df.loc['1850':'1880']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "04a48477-173d-4d7b-84c0-f05165a24b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trenddf_pi ,r_pi = artificial_trend_analysis(df_pi, forcing_estimates.loc['CMIP6-constrained','mean']*-20, hist=False, region='Europe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b31b9cb2-9df8-4dc8-8d04-8c0351f80f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "artificial_trend_analysis(df_pi, forcing_estimates.loc['CMIP6-constrained','mean']*5,intercept=10, hist=False, region='Europe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "16b921a4-5be6-4dc3-87ef-8aae9e1db8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "detrended_pi = df_pi-df_pi.mean()["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c17f8489-d5e2-4ec5-a129-fb0fae99b567",
   "metadata": {},
   "outputs": [],
   "source": [
    "detrended_pi['Europe_NorESM2-LM_ERFt'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1b745023-b209-4726-b0ff-7a929e588dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_PI['Europe_NorESM2-LM_ERFt'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "552328d0-effe-4110-9ec4-18961a520961",
   "metadata": {},
   "outputs": [],
   "source": [
    "trenddf_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e77be86c-cd07-430e-8585-89939e196818",
   "metadata": {},
   "outputs": [],
   "source": [
    "trenddf_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "82300307-5ded-4763-8154-1b29692feb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bc888a4d-ecc5-431c-9986-4b9962a1c9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "23ccd54e-e772-4cc1-ad81-49f4cbe73cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_dt.loc['1860':'1890']['Global_NorESM2-LM_ERFt'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "20efdbc9-9ef6-4fa0-893e-2080c2d7bf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [c.split('_')[1] for c in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "cc0a2d5b-a2cc-44ae-83d2-b4e8adeb5df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b4f06202-ff62-47bc-b4a7-3ac7ca16cdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "12f7b1fc-2d8a-4608-8d58-fecb14290f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(trenddf['East China_NorESM2-LM_ERFt']).plot()\n",
    "var_1950['East China_NorESM2-LM_ERFt'].plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "afa8a73b-86d3-45d6-8b44-7c7e9d187bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_1950['East China_NorESM2-LM_ERFt'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "524f5de2-62c9-431c-9c91-a09dc48aa011",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bbb630ea-1a75-4e0f-8d6c-bf4ed08be3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "-0.5*forcing_estimates.loc['CMIP6-constrained','mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "05bee7a0-8382-41c8-a2a2-55440b59f778",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(model.params[1])/(forcing_estimates.loc['CMIP6-constrained','mean'])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d9ffcdce-60e5-4869-bf2d-b57f935fcdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(np.arange(0,len(trenddf['Europe_NorESM2-LM_ERFt'])))\n",
    "\n",
    "model = sm.OLS(trenddf['East China_NorESM2-LM_ERFt'],X).fit()\n",
    "\n",
    "line = model.params[0] + model.params[1]*np.arange(0,len(trenddf['East China_NorESM2-LM_ERFt'].index))\n",
    "trenddf['East China_NorESM2-LM_ERFt'].plot(marker='.', markersize=10, linestyle='')\n",
    "plt.plot(trenddf['trend']+model.params[0])\n",
    "plt.plot(trenddf['East China_NorESM2-LM_ERFt'].index, line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ec64af8-575d-45b4-ba62-b924ed367e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "line.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "699da851-b837-44fe-9f86-015dacfd6c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(trenddf['trend']+trenddf['const']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "9257ad69-b459-45a7-9ece-6451c101aa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(np.arange(0,len(trenddf['Europe_NorESM2-LM_ERFt'])))\n",
    "\n",
    "model = sm.OLS(trenddf['Europe_NorESM2-LM_ERFt'],X).fit()\n",
    "\n",
    "line = model.params[0] + model.params[1]*np.arange(0,len(trenddf['Europe_NorESM2-LM_ERFt'].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "fe303c84-6a87-44f9-b8e1-4c1d6d292532",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.params[1]*np.arange(0,len(trenddf['Europe_NorESM2-LM_ERFt'].index)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "0f7260c9-3c7b-495c-b637-d3ab38afee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "trenddf['trend'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "154d801a-0c05-481e-92f5-6f8daffdc428",
   "metadata": {},
   "outputs": [],
   "source": [
    "trenddf['Europe_NorESM2-LM_ERFt'].plot(marker='.', markersize=10, linestyle='')\n",
    "plt.plot(trenddf['trend']+model.params[0], label='actual trend')\n",
    "plt.plot(trenddf['East China_NorESM2-LM_ERFt'].index, line, label='estimated trend')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b1ca00-7298-469c-9af2-e5cf4d27f2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "cebea68c-dec4-471d-92d7-88f6ae0098f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adf_test(timeseries):\n",
    "    print(\"Results of Dickey-Fuller Test:\")\n",
    "    dftest = adfuller(timeseries, autolag=\"AIC\")\n",
    "    dfoutput = pd.Series(\n",
    "        dftest[0:4],\n",
    "        index=[\n",
    "            \"Test Statistic\",\n",
    "            \"p-value\",\n",
    "            \"#Lags Used\",\n",
    "            \"Number of Observations Used\",\n",
    "        ],\n",
    "    )\n",
    "    for key, value in dftest[4].items():\n",
    "        dfoutput[\"Critical Value (%s)\" % key] = value\n",
    "    print(dfoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c065e574-56c5-4192-bf5d-6cfcf7673d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf_test(var_1950['East China_NorESM2-LM_ERFt'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dustysnake",
   "language": "python",
   "name": "dustysnake"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
