{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ff9404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake\n",
    "\n",
    "from workflow.scripts.utils import copy_meta_data_CMIP,transelate_aerocom_helper, regrid_global\n",
    "from pyclim_noresm.general_util_funcs import yearly_avg\n",
    "import time\n",
    "import xarray as xr\n",
    "from functools import partial\n",
    "import xesmf\n",
    "import pandas as pd\n",
    "from intake_esm.derived import DerivedVariableRegistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6281e3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_datatracker():\n",
    "    import yaml\n",
    "    find_issue = lambda d: [k for k,v in d.items() if var_id in v]\n",
    "    erfs = snakemake.config.get('variables')\n",
    "    burdens_dict = snakemake.config.get('burdens_dict')\n",
    "    burdens_vars = find_issue(burdens_dict)\n",
    "    erfs_vars = find_issue(erfs)\n",
    "    issue_vars = burdens_vars+erfs_vars\n",
    "    if not issue_vars:\n",
    "        issue_vars = [var_id]\n",
    "        \n",
    "    \n",
    "    with open(snakemake.input.data_tracker, 'r') as f:\n",
    "        data = yaml.load(f, yaml.SafeLoader)\n",
    " \n",
    "    print(data)\n",
    "    for v in issue_vars:\n",
    "        for k,requests in data.items():\n",
    "            data[k] = list(set(requests)-set(issue_vars)) \n",
    "    print(data)\n",
    "    \n",
    "    with open(snakemake.input.data_tracker, 'w') as f:\n",
    "        yaml.dump(data,f, yaml.SafeDumper,default_flow_style=False)\n",
    "    \n",
    "    raise ValueError(f\"Could not find {var_id} in, removing {','.join(issue_vars)} from data tracker \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189494cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_id = snakemake.wildcards.experiment\n",
    "mod_id = snakemake.wildcards.model\n",
    "var_id = snakemake.wildcards.variable\n",
    "freq = snakemake.wildcards.freq\n",
    "table_id = snakemake.config['table_ids'].get(var_id, snakemake.config['table_id_default'])\n",
    "if snakemake.config['model_specific_variant'].get(exp_id, None):\n",
    "    memb_id = snakemake.config['model_specific_variant'][exp_id].get(mod_id, snakemake.config['variant_default'])\n",
    "else:\n",
    "    memb_id = snakemake.config['variant_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30b00e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kind = snakemake.params.get(\"kind\", \"experiment\")\n",
    "params = snakemake.params\n",
    "accumlative_vars = params.get('accumalative_vars',None)\n",
    "use_derived_vars = snakemake.config['use_derived_vars'].get(var_id,False)\n",
    "if isinstance(use_derived_vars, dict):\n",
    "    use_derived_vars = use_derived_vars.get(mod_id, use_derived_vars['all'])\n",
    "\n",
    "\n",
    "deptotal = {\n",
    "    'depdust': { \n",
    "    'vars':['wetdust', 'drydust'],\n",
    "    'long_name': \"Total dust deposition\",\n",
    "    'standard_name' : \"total_deposition_of_dust\"\n",
    "    },\n",
    "    'depso4' :{ \n",
    "    'vars': ['wetso4', 'dryso4'],\n",
    "    'long_name': \"Total SO4 deposition\",\n",
    "    'standard_name' : \"total_deposition_of_so4\"\n",
    "    },\n",
    "    'depss' :{ \n",
    "    'vars': ['wetss', 'dryss'],\n",
    "    'long_name': \"Total Sea salt deposition\",\n",
    "    'standard_name' : \"total_deposition_of_seasalt\"\n",
    "    },\n",
    "    'depoa' : {\n",
    "    'vars' : ['wetoa', 'dryoa'],\n",
    "    'long_name': \"Total deposition of Organic Aerosols\",\n",
    "    'standard_name' : 'total_deposition_of_oa'\n",
    "    },\n",
    "    'depso2' : {\n",
    "    'vars' : ['wetso2', 'dryso2'],\n",
    "    'long_name' : \"Total deposition of SO2\",\n",
    "    'standard_name' : 'total_deposition_so2'\n",
    "    }\n",
    "}\n",
    "\n",
    "if deptotal.get(var_id, None):\n",
    "    depvar = var_id\n",
    "else:\n",
    "    depvar = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc079007",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvr = DerivedVariableRegistry()\n",
    "@dvr.register(variable='rlutaf', \n",
    "              query=dict(experiment_id=exp_id,\n",
    "                    source_id=mod_id,\n",
    "                     variable_id = ['rlutcs', 'rlut','rlutcsaf'],\n",
    "                     member_id=memb_id,\n",
    "                     )\n",
    "             )\n",
    "def calc_rlutaf(ds):\n",
    "    ds['rlutaf'] = ds['rlut'] + (ds['rlutcsaf'] - ds['rlutcs'])\n",
    "    attrs = ds['rlut'].attrs.copy()\n",
    "    ds = ds.drop(['rlut','rlutcsaf','rlutcs'])\n",
    "    ds['rlutaf'].attrs = attrs \n",
    "    ds['rlutaf'].attrs['long_name'] = 'TOA Outgoing aerosol free Longwave Radiation'\n",
    "    ds.attrs['variable_id'] = 'rlutaf'\n",
    "    return ds\n",
    "    \n",
    "@dvr.register(variable='rsutaf', \n",
    "              query=dict(experiment_id=exp_id,\n",
    "                    source_id=mod_id,\n",
    "                     variable_id = ['rsutcs', 'rsut','rsutcsaf'],\n",
    "                     member_id=memb_id,\n",
    "                     )\n",
    "             )\n",
    "def calc_rsutaf(ds):\n",
    "    ds['rsutaf'] = ds['rsut'] + (ds['rsutcsaf'] - ds['rsutcs'])\n",
    "    attrs = ds['rsut'].attrs.copy()\n",
    "    ds = ds.drop(['rsut','rsutcsaf','rsutcs'])\n",
    "    ds['rsutaf'].attrs = attrs \n",
    "    ds['rsutaf'].attrs['long_name'] = 'TOA Outgoing aerosol free Shortwave Radiation'\n",
    "    ds.attrs['variable_id'] = 'rsutaf'\n",
    "    return ds\n",
    "\n",
    "@dvr.register(variable='loaddust', \n",
    "              query=dict(experiment_id=exp_id,\n",
    "                    source_id=mod_id,\n",
    "                     variable_id = ['mmrdust', 'airmass'],\n",
    "                     member_id=memb_id,\n",
    "                     )\n",
    "             )\n",
    "def calc_loaddust(ds):\n",
    "    ds['loaddust'] = ds['airmass']*ds['mmrdust']\n",
    "    attrs = ds['mmrdust'].attrs.copy()\n",
    "    ds = ds.drop(['mmrdust','airmass'])\n",
    "    ds['loaddust'].attrs = attrs\n",
    "    ds['loaddust'].attrs['long_name'] = \"Load of Dust\"\n",
    "    ds['loaddust'].attrs['units'] = \"kg m-2\"\n",
    "    ds['loaddust'].attrs['standard_name'] = \"load_of_dust\"\n",
    "    ds.attrs['variable_id'] = 'loaddust'\n",
    "    return ds\n",
    "\n",
    "if depvar:\n",
    "    @dvr.register(variable=depvar,\n",
    "                  query=dict(experiment_id=exp_id,\n",
    "                        source_id=mod_id,\n",
    "                         variable_id = deptotal[depvar]['vars'],\n",
    "                         member_id=memb_id,\n",
    "                 ))\n",
    "    def calc_dep(ds):\n",
    "        wdp = deptotal[depvar]['vars'][0]\n",
    "        ddp = deptotal[depvar]['vars'][1]\n",
    "        ds[depvar] = ds[wdp] + ds[ddp]\n",
    "        attrs = ds[ddp].attrs.copy()\n",
    "        ds = ds.drop([ddp, wdp])\n",
    "        ds[depvar].attrs = attrs\n",
    "        ds[depvar].attrs['long_name'] = deptotal[depvar]['long_name']\n",
    "        ds[depvar].attrs['standard_name'] = deptotal[depvar]['long_name']\n",
    "        ds.attrs['variable_id'] = depvar\n",
    "        return ds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661f4593",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_derived_vars:\n",
    "    esm_cat = intake.open_esm_datastore(snakemake.input.catalog, registry=dvr)\n",
    "else:\n",
    "    esm_cat = intake.open_esm_datastore(snakemake.input.catalog, registry=dvr)\n",
    "col = esm_cat.search(experiment_id=exp_id,\n",
    "                source_id=mod_id,\n",
    "                 variable_id = var_id,\n",
    "                 member_id=memb_id,\n",
    ")\n",
    "if var_id in col.unique()['variable_id'] and (use_derived_vars==False):\n",
    "    col.derivedcat = DerivedVariableRegistry()\n",
    "    col = col.search(variable_id = var_id)\n",
    "    if var_id == 'concdust':\n",
    "        esm_cat.derivedcat = DerivedVariableRegistry()\n",
    "        col = esm_cat.search(experiment_id=exp_id,\n",
    "                source_id=mod_id,\n",
    "                 variable_id = 'loaddust',\n",
    "                 member_id=memb_id,\n",
    "                 table_id='Emon')\n",
    "    elif col.nunique()['table_id'] > 1:\n",
    "        col = col.search(table_id=table_id)\n",
    "\n",
    "        \n",
    "if col.nunique().version > 1 and not col.unique()['derived_variable_id']:\n",
    "    latest = max(col.df['version'].unique())\n",
    "    col = col.search(version=[latest])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de069031",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    ds = col.to_dataset_dict(xarray_open_kwargs={'use_cftime':True},)\n",
    "    ds = ds[list(ds.keys())[0]]\n",
    "    ds = ds.drop('member_id').squeeze()\n",
    "except IndexError:\n",
    "    update_datatracker()\n",
    "\n",
    "if col.derivedcat.values():\n",
    "    expected_variables = col.derivedcat[var_id].query['variable_id']\n",
    "    if sorted(expected_variables) != sorted(col.unique()['variable_id']):\n",
    "        update_datatracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a899e4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if var_id == 'concdust' and 'concdust' not in ds.data_vars:\n",
    "    esm_cat.derivedcat = DerivedVariableRegistry()\n",
    "    col = esm_cat.search(experiment_id=exp_id,\n",
    "                source_id=mod_id,\n",
    "                 variable_id = 'loaddust',\n",
    "                 member_id=memb_id,\n",
    "                 table_id='Emon')\n",
    "    ds = col.to_dataset_dict(xarray_open_kwargs={'use_cftime':True},)\n",
    "    ds = ds[list(ds.keys())[0]]\n",
    "    ds = ds.drop('member_id').squeeze()\n",
    "    ds = ds.rename({'loaddust':'concdust'})\n",
    "    ds.attrs['variable_id'] = 'concdust'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dbdff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.reset_coords()\n",
    "if 'ps' not in ds.data_vars and 'lev' in ds.dims:\n",
    "    col = esm_cat.search(experiment_id=exp_id,\n",
    "                source_id=mod_id,\n",
    "                 variable_id = 'ps',\n",
    "                 member_id=memb_id,\n",
    "                        table_id='Amon')\n",
    "    ps = col.to_dataset_dict(xarray_open_kwargs={'use_cftime':True},)\n",
    "    ps = ps[list(ps.keys())[0]]\n",
    "    ps = ps.drop('member_id').squeeze()\n",
    "    ds = ds.assign(ps=ps['ps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b3521d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvar_orr = set(list(ds.data_vars))\n",
    "ds_orr = ds.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d640dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_bounds(ds, variable):\n",
    "    return 'time' in set(ds.cf.get_bounds(variable).dims) - set(ds.cf[variable].dims)\n",
    "if 'lon_bnds' in ds.coords or 'lat_bnds' in ds.coords:\n",
    "    if check_bounds(ds, 'longitude') or check_bounds(ds, 'latitude'):\n",
    "        ds = ds.drop('lon_bnds')\n",
    "        ds = ds.drop('lat_bnds')\n",
    "        ds = ds.cf.add_bounds('latitude', dim='lat')\n",
    "        ds = ds.cf.add_bounds('longitude', dim='lon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a338c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regrid_dataset(ds, grid_params, grid_path):\n",
    "\n",
    "    method=grid_params.get('method','conservative')\n",
    "    if grid_path:\n",
    "        out_grid = xr.open_dataset(grid_path)\n",
    "        ds = regrid_global(ds, out_grid, method=method)\n",
    "    elif grid_params.get('dxdy',None):\n",
    "        dxdy = grid_params['dxdy']\n",
    "        ds= regrid_global(ds, lon=dxdy[0], lat=dxdy[1], method=method,ignore_degenerate=True)\n",
    "    else:\n",
    "        print('No outgrid provided!')\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70218c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if snakemake.config.get('regrid_params', None) and snakemake.params.get('regrid', True):\n",
    "    if ds.data_vars.get('lon_bnds') is not None:\n",
    "        if 'time' in ds.lon_bnds.dims:\n",
    "            ds = ds.drop('lon_bnds')\n",
    "    grid_params=snakemake.config['regrid_params']\n",
    "    regrid_func = partial(regrid_dataset,grid_params = snakemake.config['regrid_params'],\n",
    "                                            grid_path = grid_params.get('grid_path',None))\n",
    "    ds = regrid_func(ds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8444876",
   "metadata": {},
   "outputs": [],
   "source": [
    "with xr.set_options(keep_attrs=True):\n",
    "    if not ds.cf.bounds.get('lon', None):\n",
    "        ds = ds.cf.add_bounds(['lon', 'lat'])\n",
    "    if freq == 'Ayear':\n",
    "\n",
    "        data=ds\n",
    "        vname = ds.variable_id\n",
    "        with xr.set_options(keep_attrs=True):\n",
    "            if data[vname].units == 'kg m-2 s-1': # annual emission / deposition \n",
    "                data=data[data.variable_id].resample(time='Y').mean()*365*24*60*60 # convert to kg m-2 yr-1\n",
    "                data.attrs['units'] = '{} year-1'.format(' '.join(data.attrs['units'].split(' ')[:-1]))\n",
    "                data = data.to_dataset(name=vname)\n",
    "                data.attrs = ds.attrs.copy()\n",
    "                data.attrs['history'] = ds.attrs.get('history', '') + f', annual average converted to kg m-2 yr-1'\n",
    "            \n",
    "            else:\n",
    "                data=data[data.variable_id].resample(time='Y').mean()\n",
    "                data = data.to_dataset(name=vname)\n",
    "                data.attrs = ds.attrs.copy()\n",
    "                data.attrs['history'] = data.attrs.get('history','') + f', annual average'    \n",
    "            \n",
    "            if 'ps' in ds.data_vars:\n",
    "                ps = ds['ps'].resample(time='Y').mean().copy()\n",
    "                data = data.assign(ps=ps)\n",
    "        t=data.time.dt.strftime('%Y')\n",
    "        data = data.assign_coords({'time':xr.cftime_range(start=str(t[0].values), end= str(t[-1].values), freq='YS')})\n",
    "        data = data.assign({ds.cf.bounds['lon'][0]:ds[ds.cf.bounds['lon'][0]]})\n",
    "        data = data.assign({ds.cf.bounds['lat'][0]:ds[ds.cf.bounds['lat'][0]]})\n",
    "        if 'time_bnds' in ds.data_vars:\n",
    "            data = ds.drop_vars('time_bnds')\n",
    "        if snakemake.params.get('regrid', True):\n",
    "            remove_vars = {'time_bnds', 'lon_bnds', 'lat_bnds'}\n",
    "        else:\n",
    "            remove_vars = {}\n",
    "    elif freq == 'clim':\n",
    "        t0 = data.time[0].dt.strftime('%Y/%m').values\n",
    "        t1 = data.time[0].dt.strftime('%Y/%m').values\n",
    "        data = data.groupby('time.month').mean('time')\n",
    "        data[data.variable_id].attrs['history'] = data[data.variable_id].attrs.get('history','') + f', clim mean {t0}-{t1}'\n",
    "        if wildcards.freq=='2010':\n",
    "            import cftime\n",
    "            import pandas as pd\n",
    "            data = data.rename(month='time')\n",
    "            cftimes = cftime.date2num(pd.date_range('2010-01-31','2010-12-31', freq='M').to_list(),\n",
    "                                              'days since 2010-01-01', \n",
    "                                                  has_year_zero=False, calendar = 'gregorian')\n",
    "            data = data.assign_coords(time=cftimes)\n",
    "            data.time.attrs['units'] = 'days since 2010-01-01'\n",
    "        dvar_attrs = copy_meta_data_CMIP(data[var_id].attrs)\n",
    "        \n",
    "    elif freq == 'Amon':\n",
    "        data = ds\n",
    "        if 'time_bnds' in ds.data_vars:\n",
    "            data = ds.drop_vars('time_bnds')\n",
    "        if snakemake.params.get('regrid', True):\n",
    "            remove_vars = {'time_bnds', 'lon_bnds', 'lat_bnds'}\n",
    "        else:\n",
    "            remove_vars = {}\n",
    "    else:\n",
    "        raise(ValueError(f'{wildcards.freq} is an invalid frequency'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0474c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'orog' in ds.data_vars:\n",
    "    data = data.assign(orog=ds['orog'].copy())\n",
    "dvar_regrid = set(list(data.data_vars))\n",
    "\n",
    "lost_vars = list(dvar_orr-dvar_regrid-remove_vars)\n",
    "\n",
    "if lost_vars:\n",
    "    data = data.assign({v : ds_orr[v] for v in lost_vars})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7a5003",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a834182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.attrs['frequency'] = snakemake.wildcards.freq\n",
    "data.to_netcdf(snakemake.output.outpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "e0c7d92e0a4d3659e3b438675286b7c84dca6ad7edb4ab471110fdd618f527c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
