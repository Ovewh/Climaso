{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78ff9404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake\n",
    "\n",
    "from workflow.scripts.utils import copy_meta_data_CMIP,transelate_aerocom_helper, regrid_global\n",
    "from pyclim_noresm.general_util_funcs import yearly_avg\n",
    "import time\n",
    "import xarray as xr\n",
    "from functools import partial\n",
    "import xesmf\n",
    "import pandas as pd\n",
    "from intake_esm.derived import DerivedVariableRegistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "189494cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_id = snakemake.wildcards.experiment\n",
    "mod_id = snakemake.wildcards.model\n",
    "var_id = snakemake.wildcards.variable\n",
    "freq = snakemake.wildcards.freq\n",
    "table_id = snakemake.config['table_ids'].get(var_id, snakemake.config['table_id_default'])\n",
    "if snakemake.config['model_specific_variant'].get(exp_id, None):\n",
    "    memb_id = snakemake.config['model_specific_variant'][exp_id].get(mod_id, snakemake.config['variant_default'])\n",
    "else:\n",
    "    memb_id = snakemake.config['variant_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e30b00e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kind = snakemake.params.get(\"kind\", \"experiment\")\n",
    "params = snakemake.params\n",
    "accumlative_vars = params.get('accumalative_vars',None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc079007",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvr = DerivedVariableRegistry()\n",
    "@dvr.register(variable='rlutaf', \n",
    "              query=dict(experiment_id=exp_id,\n",
    "                    source_id=mod_id,\n",
    "                     variable_id = ['rlutcs', 'rlut','rlutcsaf'],\n",
    "                     member_id=memb_id,\n",
    "                     )\n",
    "             )\n",
    "def calc_rlutaf(ds):\n",
    "    ds['rlutaf'] = ds['rlut'] + (ds['rlutcsaf'] - ds['rlutcs'])\n",
    "    attrs = ds['rlut'].attrs.copy()\n",
    "    ds = ds.drop(['rlut','rlutcsaf','rlutcs'])\n",
    "    ds['rlutaf'].attrs = attrs \n",
    "    ds['rlutaf'].attrs['long_name'] = 'TOA Outgoing aerosol free Longwave Radiation'\n",
    "    ds.attrs['variable_id'] = 'rlutaf'\n",
    "    return ds\n",
    "    \n",
    "@dvr.register(variable='rsutaf', \n",
    "              query=dict(experiment_id=exp_id,\n",
    "                    source_id=mod_id,\n",
    "                     variable_id = ['rsutcs', 'rsut','rsutcsaf'],\n",
    "                     member_id=memb_id,\n",
    "                     )\n",
    "             )\n",
    "def calc_rsutaf(ds):\n",
    "    ds['rsutaf'] = ds['rsut'] + (ds['rsutcsaf'] - ds['rsutcs'])\n",
    "    attrs = ds['rsut'].attrs.copy()\n",
    "    ds = ds.drop(['rsut','rsutcsaf','rsutcs'])\n",
    "    ds['rsutaf'].attrs = attrs \n",
    "    ds['rsutaf'].attrs['long_name'] = 'TOA Outgoing aerosol free Shortwave Radiation'\n",
    "    ds.attrs['variable_id'] = 'rsutaf'\n",
    "    return ds\n",
    "\n",
    "@dvr.register(variable='loaddust', \n",
    "              query=dict(experiment_id=exp_id,\n",
    "                    source_id=mod_id,\n",
    "                     variable_id = ['mmrdust', 'airmass'],\n",
    "                     member_id=memb_id,\n",
    "                     )\n",
    "             )\n",
    "\n",
    "def calc_loaddust(ds):\n",
    "    ds['loaddust'] = ds['airmass']*ds['mmrdust']\n",
    "    attrs = ds['mmrdust'].copy()\n",
    "    \n",
    "    ds['loaddust'].attrs['long_name'] = \"Load of Dust\"\n",
    "    ds['loaddust'].attrs['units'] = \"kg m-2\"\n",
    "    ds['loaddust'].attrs['standard_name'] = \"load_of_dust\"\n",
    "    ds.attrs['variable_id'] = 'loaddust'\n",
    "    return ds\n",
    "\n",
    "\n",
    "@dvr.register(variable='concdust', \n",
    "              query=dict(experiment_id=exp_id,\n",
    "                    source_id=mod_id,\n",
    "                     variable_id = ['mmrdust', 'airmass'],\n",
    "                     member_id=memb_id,\n",
    "                     )\n",
    "             )\n",
    "def calc_concdust(ds):\n",
    "    ds['loaddust'] = ds['airmass']*ds['mmrdust']\n",
    "    attrs = ds['mmrdust'].copy()\n",
    "    ds = ds.drop(['mmrdust','airmass', 'ps'])\n",
    "    ds = ds.sum(dim=ds.cf['Z'].name, keep_attrs=True)\n",
    "    ds = ds.rename({'loaddust':'concdust'})\n",
    "    ds['concdust'].attrs['long_name'] = \"Integrated Load of Dust\"\n",
    "    ds['concdust'].attrs['units'] = \"kg m-2\"\n",
    "    ds['concdust'].attrs['standard_name'] = \"integrated_load_of_dust\"\n",
    "    ds.attrs['variable_id'] = 'concdust'\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "661f4593",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "esm_cat = intake.open_esm_datastore(snakemake.input.catalog, registry=dvr)\n",
    "col = esm_cat.search(experiment_id=exp_id,\n",
    "                source_id=mod_id,\n",
    "                 variable_id = var_id,\n",
    "                 member_id=memb_id,\n",
    ")\n",
    "if col.nunique().table_id > 1:\n",
    "    col = col.search(table_id=table_id)\n",
    "\n",
    "if col.nunique().version > 1:\n",
    "    latest = max(col.df['version'].unique())\n",
    "    col = col.search(version=[latest])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de069031",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = col.to_dataset_dict(xarray_open_kwargs={'use_cftime':True})\n",
    "ds = ds[list(ds.keys())[0]]\n",
    "ds = ds.drop('member_id').squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10328682",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvar_orr = set(list(ds.data_vars))\n",
    "ds_orr = ds.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd2f68f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regrid_dataset(ds, grid_params, grid_path):\n",
    "\n",
    "    method=grid_params.get('method','conservative')\n",
    "    if grid_path:\n",
    "        out_grid = xr.open_dataset(grid_path)\n",
    "        ds = regrid_global(ds, out_grid, method=method)\n",
    "    elif grid_params.get('dxdy',None):\n",
    "        dxdy = grid_params['dxdy']\n",
    "        ds= regrid_global(ds, lon=dxdy[0], lat=dxdy[1], method=method,ignore_degenerate=True)\n",
    "    else:\n",
    "        print('No outgrid provided!')\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6d640dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_bounds(ds, variable):\n",
    "    return 'time' in set(ds.cf.get_bounds(variable).dims) - set(ds.cf[variable].dims)\n",
    "if 'lon_bnds' in ds.coords or 'lat_bnds' in ds.coords:\n",
    "    if check_bounds(ds, 'longitude') or check_bounds(ds, 'latitude'):\n",
    "        ds = ds.drop('lon_bnds')\n",
    "        ds = ds.drop('lat_bnds')\n",
    "        ds = ds.cf.add_bounds('latitude', dim='lat')\n",
    "        ds = ds.cf.add_bounds('longitude', dim='lon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a70218c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if snakemake.config.get('regrid_params', None) and snakemake.params.get('regrid', True):\n",
    "    grid_params=snakemake.config['regrid_params']\n",
    "    regrid_func = partial(regrid_dataset,grid_params = snakemake.config['regrid_params'],\n",
    "                                            grid_path = grid_params.get('grid_path',None))\n",
    "    ds = regrid_func(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "df58f982",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvar_regrid = set(list(ds.data_vars))\n",
    "\n",
    "lost_vars = list(dvar_orr-dvar_regrid)\n",
    "\n",
    "if lost_vars:\n",
    "    ds = ds.assign({v : ds_orr[v] for v in lost_vars})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c8444876",
   "metadata": {},
   "outputs": [],
   "source": [
    "with xr.set_options(keep_attrs=True):\n",
    "    if not ds.cf.bounds.get('lon', None):\n",
    "        ds = ds.cf.add_bounds(['lon', 'lat'])\n",
    "    if freq == 'Ayear':\n",
    "        if 'time_bnds' in ds.data_vars:\n",
    "            data = ds.drop_vars('time_bnds')\n",
    "        if var_id in accumlative_vars:\n",
    "            data=ds\n",
    "            vname = ds.variable_id\n",
    "            data=data[data.variable_id].resample(time='Y').mean()*365*24*60*60\n",
    "            data.attrs['units'] = '{} year-1'.format(' '.join(data.attrs['units'].split(' ')[:-1]))\n",
    "            data = data.to_dataset(name=vname)\n",
    "            data.attrs['history'] = ds.attrs.get('history', '') + f', accumulated over a year'\n",
    "            dvar_attrs = copy_meta_data_CMIP(data[var_id].attrs)\n",
    "        else:\n",
    "            #data[data.variable_id] = yearly_avg(data[data.variable_id])\n",
    "            data=ds.resample(time='Y').mean()\n",
    "            data.attrs['history'] = data.attrs.get('history','') + f', annual average'\n",
    "            dvar_attrs = copy_meta_data_CMIP(data[var_id].attrs)\n",
    "        data = data.assign({ds.cf.bounds['lon'][0]:ds[ds.cf.bounds['lon'][0]]})\n",
    "        data = data.assign({ds.cf.bounds['lat'][0]:ds[ds.cf.bounds['lat'][0]]})\n",
    "    elif freq == 'clim':\n",
    "        t0 = data.time[0].dt.strftime('%Y/%m').values\n",
    "        t1 = data.time[0].dt.strftime('%Y/%m').values\n",
    "        data = data.groupby('time.month').mean('time')\n",
    "        data[data.variable_id].attrs['history'] = data[data.variable_id].attrs.get('history','') + f', clim mean {t0}-{t1}'\n",
    "        if wildcards.freq=='2010':\n",
    "            import cftime\n",
    "            import pandas as pd\n",
    "            data = data.rename(month='time')\n",
    "            cftimes = cftime.date2num(pd.date_range('2010-01-31','2010-12-31', freq='M').to_list(),\n",
    "                                              'days since 2010-01-01', \n",
    "                                                  has_year_zero=False, calendar = 'gregorian')\n",
    "            data = data.assign_coords(time=cftimes)\n",
    "            data.time.attrs['units'] = 'days since 2010-01-01'\n",
    "        dvar_attrs = copy_meta_data_CMIP(data[var_id].attrs)\n",
    "        \n",
    "    elif freq == 'Amon':\n",
    "        data = ds\n",
    "    else:\n",
    "        raise(ValueError(f'{wildcards.freq} is an invalid frequency'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a834182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.attrs['frequency'] = snakemake.wildcards.freq\n",
    "data.to_netcdf(snakemake.output.outpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
