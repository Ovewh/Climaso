{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "901fa3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as mpl\n",
    "import xesmf as xe\n",
    "from workflow.scripts.utils import regrid_global\n",
    "import numpy as np\n",
    "from pyclim_noresm.general_util_funcs import global_avg\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy.optimize import curve_fit\n",
    "from numpy.linalg import lstsq\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "364fd3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(paths, tag='experiment_id'):\n",
    "    dsets = []\n",
    "    for p in paths:\n",
    "        ds = xr.open_dataset(p)\n",
    "        ds = ds.cf.add_bounds(['lon','lat'])\n",
    "        grid_params = snakemake.config['regrid_params']\n",
    "        method=grid_params.get('method','conservative')\n",
    "\n",
    "        dxdy = grid_params['dxdy']\n",
    "        ds = regrid_global(ds, lon=dxdy[0], lat=dxdy[1], method=method)\n",
    "        da = ds[ds.variable_id]\n",
    "#         return da\n",
    "        da = da.rename(f'{ds.variable_id}_{ds.attrs[tag]}')\n",
    "        da.attrs['source_id'] = ds.source_id \n",
    "        da.attrs['experiment_id'] = ds.experiment_id\n",
    "        da.attrs['variable_id'] = ds.variable_id\n",
    "        da = da.assign_coords(time=np.arange(0, len(da.time)))\n",
    "#         da = da.rename(year='time')\n",
    "        dsets.append(da)\n",
    "    out_da = xr.merge(dsets)\n",
    "    return out_da\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50e1092a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rad_noresm = read_data(snakemake.input.noresm_rad)\n",
    "\n",
    "load_nor = read_data(snakemake.input.noresm_load)\n",
    "\n",
    "clt_nor = read_data(snakemake.input.noresm_clt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "102ca843",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_noresm = list({rad_noresm[d].experiment_id for d in rad_noresm.data_vars})\n",
    "variables = list({load_nor[v].variable_id for v in load_nor.data_vars})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e4f5ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_toa_imbalance(ds_rad, experiments,ds_load=None,tag='cs', subtract_mean_dTOA=True, sw=False):\n",
    "    toa_imbalance = []\n",
    "    loads = []\n",
    "    for exp in experiments:\n",
    "        if sw ==True:\n",
    "            temp_da = (np.abs(ds_rad[f'rsdt_{exp}'].dropna(dim='time')) \n",
    "#                    - np.abs(ds_rad[f'rlut{tag}_{exp}'].dropna(dim='time')) \n",
    "                   - np.abs(ds_rad[f'rsut{tag}_{exp}'].dropna(dim='time')))\n",
    "        \n",
    "        else:\n",
    "            temp_da = (np.abs(ds_rad[f'rsdt_{exp}'].dropna(dim='time')) \n",
    "                   - np.abs(ds_rad[f'rlut{tag}_{exp}'].dropna(dim='time')) \n",
    "                   - np.abs(ds_rad[f'rsut{tag}_{exp}'].dropna(dim='time')))\n",
    "        \n",
    "        if ds_load:\n",
    "            load_da = ds_load[f'mmrdust_{exp}'].dropna(dim='time')*ds_load[f'airmass_{exp}'].dropna(dim='time')\n",
    "            load_da = load_da.sum(dim='lev')\n",
    "    #         return load_da\n",
    "            load_da = global_avg(load_da)\n",
    "            load_da = load_da -load_da.mean()\n",
    "            load = load_da.to_dataset(name=f'loaddust_{exp}')\n",
    "            loads.append(load)\n",
    "        temp_da = global_avg(temp_da)\n",
    "        if subtract_mean_dTOA:\n",
    "            temp_da = temp_da - temp_da.mean()\n",
    "        temp_rad = temp_da.to_dataset(name=f'dTOA_{exp}')\n",
    "        \n",
    "        toa_imbalance.append(temp_rad)\n",
    "    load_im=xr.merge(toa_imbalance+loads)\n",
    "#     if subtract_mean == True:\n",
    "#         load_im=load_im-load_im.mean()\n",
    "    \n",
    "    return load_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b2af277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loads(ds, variable, experiment):\n",
    "    dsets = []\n",
    "    for v in variables:\n",
    "        for exp in experiment: \n",
    "            if v == 'airmass':\n",
    "                continue\n",
    "            else:\n",
    "                dsmmr = ds[f'{v}_{exp}'].dropna(dim='time')\n",
    "                dsair = ds[f'airmass_{exp}'].dropna(dim='time')\n",
    "#                 print(dsair.shape)\n",
    "                load = dsmmr*dsair\n",
    "                load = load.sum(dim='lev')\n",
    "                \n",
    "                load = global_avg(load)\n",
    "                load = load-load.mean()\n",
    "                load = load.to_dataset(name=f'load{v[3:]}_{exp}')\n",
    "                dsets.append(load)\n",
    "    ds = xr.merge(dsets)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff969907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ec_load_im = calc_toa_imbalance(rad_ec,exp_ec,ds_load=load_ec)\n",
    "nor_im = calc_toa_imbalance(rad_noresm, exp_noresm)\n",
    "nor_im_sw = calc_toa_imbalance(rad_noresm, exp_noresm, sw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79e5728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nor_clt = global_avg(clt_nor).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70bec180",
   "metadata": {},
   "outputs": [],
   "source": [
    "clt = nor_clt.replace(0.0,np.nan).values.ravel()\n",
    "clt = clt[~np.isnan(clt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "333cd899",
   "metadata": {},
   "outputs": [],
   "source": [
    "nor_load = calc_loads(load_nor, variables, exp_noresm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e94a5f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_data(ds_im,ds_load, experiments, variable):\n",
    "    df = ds_im.to_dataframe()\n",
    "    dfl = ds_load.to_dataframe()\n",
    "    dfs = []\n",
    "    \n",
    "    for exp in experiments:\n",
    "        tdf = df[f'dTOA_{exp}'].to_frame()\n",
    "        tdfl = dfl[f'{variable}_{exp}']\n",
    "        tdf[f'{variable}_{exp}'] = tdfl\n",
    "        \n",
    "\n",
    "        tdf = tdf.dropna()\n",
    "#         tdf=tdf[(np.abs(stats.zscore(tdf)) < 3).all(axis=1)]\n",
    "#         return tdf, tdfl\n",
    "#         return tdf\n",
    "        tdf = tdf.rename(columns={f'{variable}_{exp}':variable,f'dTOA_{exp}':'dTOA'})\n",
    "        dfs.append(tdf)\n",
    "#     ts_load_ano = [df[[f'loaddust_{exp}']] for exp in experiments]\n",
    "#     ts_dTOA_ano = [df[f'dTOA_{exp}'] for exp in experiments]\n",
    "    df = pd.concat(dfs).reset_index()\n",
    "#     ts_dTOA = pd.concat(ts_dTOA_ano).reset_index()\n",
    "#     return tdf\n",
    "    df = df.drop(columns='time')\n",
    "    df=df[(np.abs(stats.zscore(df['dTOA'])) < 3)]\n",
    "#      = ts_load.drop(columns='time')\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "99b8a97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nor_loadss_dTOA = stack_data(nor_im, nor_load,exp_noresm,'loadss')\n",
    "nor_loadsoa_dTOA = stack_data(nor_im, nor_load,exp_noresm,'loadsoa')\n",
    "nor_loadso4_dTOA = stack_data(nor_im, nor_load,exp_noresm,'loadso4')\n",
    "\n",
    "nor_loadbc_dTOA = stack_data(nor_im, nor_load,exp_noresm,'loadbc')\n",
    "nor_loaddust_dTOA = stack_data(nor_im, nor_load,exp_noresm,'loaddust')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "494c1c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nor_clt_dTOA = pd.DataFrame(clt, columns=['clt'])\n",
    "nor_clt_dTOA = nor_clt_dTOA-nor_clt_dTOA.mean()\n",
    "nor_clt_dTOA['dTOA'] = load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "43e16ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nor_clt_dTOA['dTOA'] = nor_loadbc_dTOA['dTOA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40889431",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_fit_numpy(df,variable,regularized = True):\n",
    "    a,c = np.polyfit(df[variable], df['dTOA'],1)\n",
    "#     model = sm.OLS(df['dTOA'],X, missing='drop')\n",
    "    return a,c,a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2486590",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_fit_scipy(df,variable,regularized = True):\n",
    "    x=df[variable]\n",
    "    y= df['dTOA']\n",
    "    res=scipy.stats.linregress(x, y)\n",
    "#  'dTOA'],bounds=(0, [3., 1., 0.5]))   model = sm.OLS(df['dTOA'],X, missing='drop')\n",
    "    return res, res.slope, res.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b424c0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fit(df,variable,regularized = True):\n",
    "    X = sm.add_constant(df[variable])\n",
    "    model = sm.OLS(df['dTOA'],X, missing='drop')\n",
    "    if regularized:\n",
    "        result = model.fit_regularized(L1_wt=1)\n",
    "    else:\n",
    "        result = model.fit()\n",
    "    return result, result.params.values[1], result.params.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "18084dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fit():\n",
    "    nor_loadss_dTOA = stack_data(nor_im, nor_load,exp_noresm,'loadss')\n",
    "    nor_loadsoa_dTOA = stack_data(nor_im, nor_load,exp_noresm,'loadsoa')\n",
    "    nor_loadso4_dTOA = stack_data(nor_im, nor_load,exp_noresm,'loadso4')\n",
    "\n",
    "    nor_loadbc_dTOA = stack_data(nor_im, nor_load,exp_noresm,'loadbc')\n",
    "    nor_loaddust_dTOA = stack_data(nor_im, nor_load,exp_noresm,'loaddust')\n",
    "    dfs = [nor_loadss_dTOA, nor_loadso4_dTOA,nor_loaddust_dTOA,nor_clt_dTOA]\n",
    "    variable = ['loadss', 'loadso4','loaddust']\n",
    "    fig,ax = plt.subplots(figsize=(14,4.5), ncols=len(variable))\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    xn = np.linspace(-1,1,100)\n",
    "    xlims=[(-8e-7,8e-7),(-1e-7, 1e-7),(-2e-6, 2e-6),(1,-1)]\n",
    "    for axi, v, df,xlim in zip(ax, variable, dfs, xlims):\n",
    "        res_nor, c_nor,x_nor = make_fit_scipy(df, v,False)\n",
    "        props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "        axi.scatter(df[v],df['dTOA'], s=5)\n",
    "        yn = np.polyval([c_nor, x_nor], xn)\n",
    "        axi.plot(xn,yn, linewidth=3, color='grey')\n",
    "        axi.set_ylim(-0.5,0.5)\n",
    "        axi.set_xlim(xlim)\n",
    "        axi.set_title(v)\n",
    "        axi.text(0.17, 0.08, f'$R^2 = $ {res_nor.rvalue**2:.2f} \\n nobs = {len(df)}', \n",
    "               va='center', ha='center', transform=axi.transAxes)\n",
    "        axi.text(0.5,0.92, f'dTOA={c_nor:.2E} $* \\;C_{{v}}$',\n",
    "              va='center', ha='center', transform=axi.transAxes,fontsize=14, bbox=props)\n",
    "        axi.set_xlabel('Load anomaly \\n [kg m-2]')\n",
    "    \n",
    "    ax[0].set_ylabel('TOA imbalance [W m-2]')\n",
    "plot_fit()\n",
    "plt.savefig(snakemake.output.toa_load_png, bbox_inches='tight', dpi=144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab4b70b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fit_sw():\n",
    "    nor_loadss_dTOA = stack_data(nor_im_sw, nor_load,exp_noresm,'loadss')\n",
    "    nor_loadsoa_dTOA = stack_data(nor_im_sw, nor_load,exp_noresm,'loadsoa')\n",
    "    nor_loadso4_dTOA = stack_data(nor_im_sw, nor_load,exp_noresm,'loadso4')\n",
    "\n",
    "    nor_loadbc_dTOA = stack_data(nor_im_sw, nor_load,exp_noresm,'loadbc')\n",
    "    nor_loaddust_dTOA = stack_data(nor_im_sw, nor_load,exp_noresm,'loaddust')\n",
    "    dfs = [nor_loadss_dTOA, nor_loadso4_dTOA,nor_loaddust_dTOA]\n",
    "    variable = ['loadss', 'loadso4','loaddust']\n",
    "    fig,ax = plt.subplots(figsize=(14,4.5), ncols=len(variable))\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    xn = np.linspace(-10e-4,10e-4,100)\n",
    "    xlims=[(-8e-7,8e-7),(-1e-7, 1e-7),(-2e-6, 2e-6),]\n",
    "    for axi, v, df,xlim in zip(ax, variable, dfs, xlims):\n",
    "        res_nor, c_nor,x_nor = make_fit_scipy(df, v,False)\n",
    "        props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "        axi.scatter(df[v],df['dTOA'], s=5)\n",
    "        yn = np.polyval([c_nor, x_nor], xn)\n",
    "        axi.plot(xn,yn, linewidth=3, color='grey')\n",
    "        axi.set_ylim(-0.5,0.5)\n",
    "        axi.set_xlim(xlim)\n",
    "        axi.set_title(v)\n",
    "        axi.text(0.17, 0.08, f'$R^2 = $ {res_nor.rvalue**2:.2f} \\n nobs = {len(df)}', \n",
    "               va='center', ha='center', transform=axi.transAxes)\n",
    "        axi.text(0.5,0.92, f'dTOA={c_nor:.2E} $* \\;C_{{v}}$',\n",
    "              va='center', ha='center', transform=axi.transAxes,fontsize=14, bbox=props)\n",
    "        axi.set_xlabel('Load anomaly \\n [kg m-2]')\n",
    "    \n",
    "    ax[0].set_ylabel('TOA imbalance [W m-2]')\n",
    "plot_fit_sw()\n",
    "plt.savefig(snakemake.output.toa_load_sw_png, bbox_inches='tight', dpi=144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7e85ab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "val=False\n",
    "if val:\n",
    "    histSST = read_data(snakemake.input.histSST_rad, tag='source_id')\n",
    "\n",
    "    mmr_mass_hist = read_data(snakemake.input.histSST_load, tag='source_id')\n",
    "\n",
    "    models = list({histSST[d].attrs['source_id'] for d in histSST.data_vars})\n",
    "\n",
    "    def calc_load(mmr_air, models):\n",
    "        dsets = []\n",
    "        for model in models:\n",
    "            ds_load = mmr_air[f'mmrdust_{model}']*mmr_air[f'airmass_{model}']\n",
    "            ds_load = ds_load.sum(dim='lev')\n",
    "            ds_load = global_avg(ds_load)\n",
    "            ds_load.attrs['units'] = 'kg m-2'\n",
    "            ds_load.attrs['long_name'] = 'Load of Dust'\n",
    "            ds_load = ds_load.to_dataset(name=f'loaddust_{model}')\n",
    "            dsets.append(ds_load)\n",
    "        ds = xr.merge(dsets)\n",
    "        return ds\n",
    "\n",
    "\n",
    "\n",
    "    histSST_imbalance_cs = calc_toa_imbalance(histSST,models,tag='cs', subtract_mean_dTOA=False)\n",
    "\n",
    "    histSST_imbalance_cs\n",
    "\n",
    "    res_nor, c_nor,x_nor = make_fit(nor_load_dTOA, False)\n",
    "    res_ec, c_ec,x_ec = make_fit(ec_load_dTOA, False)\n",
    "    res_mpi, c_mpi, x_mpi = make_fit(mpi_load_dTOA, False)\n",
    "\n",
    "    loads_histSST = calc_load(mmr_mass_hist, models)\n",
    "\n",
    "    def create_validation_data(loading, dTOA, t_slice=None):\n",
    "        if t_slice:\n",
    "            loading = loading.isel(time=t_slice)\n",
    "            dTOA = dTOA.isel(time=t_slice)\n",
    "        else:\n",
    "            loading = loading.isel(time=slice(0,30))\n",
    "            dTOA = dTOA.sel(time=slice(0,30))\n",
    "\n",
    "        loading = loading - loading.mean()\n",
    "        loading = loading.rename('loaddust')\n",
    "    #     dTOA = dTOA - dTOA.mean()\n",
    "        dTOA = dTOA.to_dataset(name='dTOA')\n",
    "        dfTOA = dTOA.to_pandas()\n",
    "        dfTOA['loaddust'] = loading.to_pandas()\n",
    "    #     dfloading = \n",
    "        return dfTOA\n",
    "\n",
    "    nor_val = create_validation_data(loads_histSST['loaddust_NorESM2-LM'], histSST_imbalance_cs['dTOA_NorESM2-LM'])\n",
    "    nor_val['predicted'] = res_nor.predict(sm.add_constant(nor_val['loaddust']))\n",
    "    mpi_val = create_validation_data(loads_histSST['loaddust_MPI-ESM-1-2-HAM'], \n",
    "                                     histSST_imbalance_cs['dTOA_MPI-ESM-1-2-HAM'], slice(-40,-10))\n",
    "    mpi_val['predicted'] = res_mpi.predict(sm.add_constant(mpi_val['loaddust']))\n",
    "\n",
    "    ec_val = create_validation_data(loads_histSST['loaddust_EC-Earth3-AerChem'], \n",
    "                                     histSST_imbalance_cs['dTOA_EC-Earth3-AerChem'])\n",
    "    ec_val['predicted'] = res_mpi.predict(sm.add_constant(ec_val['loaddust']))\n",
    "\n",
    "    dhTOA_mpi = histSST_imbalance_cs['dTOA_MPI-ESM-1-2-HAM'].isel(time=slice(0,30)) - histSST_imbalance_cs['dTOA_MPI-ESM-1-2-HAM'].isel(time=slice(0,30)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e8804c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if val:\n",
    "    ax = plt.gca()\n",
    "    mpi_load_im['loaddust_piClim-aer'].plot(ax=ax)\n",
    "    mpi_load_im['loaddust_piClim-2xdust'].plot(ax=ax)\n",
    "    mpi_load_im['loaddust_piClim-control'].plot(ax=ax)\n",
    "    mpi_val['loaddust'].plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "de9eb5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if val:\n",
    "    ax = plt.gca()\n",
    "\n",
    "    ax.plot(res_mpi.predict(sm.add_constant(mpi_load_im['loaddust_piClim-aer'])))\n",
    "    ax.plot(res_mpi.predict(sm.add_constant(mpi_load_im['loaddust_piClim-2xdust'])))\n",
    "    ax.plot(res_mpi.predict(sm.add_constant(mpi_load_im['loaddust_piClim-control'])))\n",
    "    (mpi_val['predicted']).plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "be0452de",
   "metadata": {},
   "outputs": [],
   "source": [
    "if val:\n",
    "    ax=plt.gca()\n",
    "    # mpi_no_dust.plot(ax=ax,marker='o', label='no dust')\n",
    "    ((mpi_val['dTOA']-mpi_val['dTOA'].mean())-mpi_val['predicted']).plot(ax=ax, marker='s', label='dTOA histSST')\n",
    "    ((mpi_val['dTOA']-mpi_val['dTOA'].mean())).plot(ax=ax, marker='s', label='dTOA histSST')\n",
    "    # ax.set_ylim(-0.6, 0.6)\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1fe6245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if val:\n",
    "    mpi_no_dust_hist = (dhTOA_mpi-\n",
    "                        res_mpi.predict(sm.add_constant(mpi_val['loaddust'])))\n",
    "\n",
    "    ax = plt.gca()\n",
    "    dhTOA_mpi.plot(ax=ax)\n",
    "    mpi_no_dust_hist.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8133704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if val:\n",
    "    ax = plt.gca()\n",
    "    # mpi_val['predicted'].plot(ax=ax)\n",
    "    (mpi_val['dTOA']-mpi_val['dTOA'].mean()).plot(ax=ax)\n",
    "    (mpi_val['dTOA']-(mpi_val['predicted']+mpi_val['dTOA'].mean())).plot(ax=ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "5252e5327a2efbab7c42f5d52cb87d9bedc44c7d9d6a615ebff0e5d85896cfce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
